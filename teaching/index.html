<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> teaching | Lesia Semenova </title> <meta name="author" content="Lesia Semenova"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lesiasemenova.github.io/teaching/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Lesia </span> Semenova </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/group/">group </a> </li> <li class="nav-item active"> <a class="nav-link" href="/teaching/">teaching <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/misc/">misc </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <p class="post-description"></p> </header> <article> <div style="text-align:center; margin: 2rem 0 1.5rem 0;"> <h1 style="margin-bottom:0.25rem;">Interpretable and Explainable AI</h1> <div style="font-size:1.05rem; opacity:0.85;">Course for Graduate students, Spring 2026</div> </div> <section> <p> Machine learning models increasingly shape decisions that affect real people: medical diagnoses, hiring and lending decisions, content moderation, legal risk assessment, and scientific discovery. At the same time, the models we rely on, including deep neural networks, foundation models, and large language models, are becoming more complex, less transparent, and harder to reason about. This tension raises a fundamental question: <em>how can we understand, trust, and responsibly deploy models whose internal logic is opaque, fragile, or underspecified?</em> </p> <p> Three distinct paradigms have emerged in response. <strong>Interpretable AI</strong> focuses on designing models that are inherently understandable; <strong>Explainable AI (XAI)</strong> seeks to provide post-hoc summaries of complex “black-box” models; and <strong>Mechanistic Interpretability</strong> attempts to reverse-engineer the internal circuits of neural networks. These approaches offer different guarantees and serve different goals. </p> <p> This course is motivated by three observations: (i) accuracy alone is no longer sufficient; (ii) not all explanations are created equal; and (iii) many distinct models can fit the same data equally well yet behave very differently. Understanding these effects (often referred to as the <em>Rashomon effect</em>) is essential for building trustworthy machine learning systems, especially in modern overparameterized models. </p> <p> <strong>The goal of this course is therefore not merely to introduce a collection of interpretability and explainability methods, but to develop judgment:</strong> </p> <ul> <li>When should we prefer inherently interpretable models over post-hoc explanations?</li> <li>What do popular methods like SHAP or LIME actually guarantee, and what do they not?</li> <li>How do explanations interact with robustness, fairness, or privacy?</li> <li>How do we move from treating models as black boxes toward mechanistic interpretability and circuit-level understanding?</li> <li>What does “understanding” mean for large language models and other generative systems?</li> <li>How should understandability be evaluated, and for whom?</li> </ul> <p> By the end of the course, students should be able to critically assess interpretability claims, choose appropriate methods for a given context, and reason clearly about the limits of explanation in modern AI systems. </p> </section> <p><strong>Time and room.</strong> Mondays 12:10–3:10 pm, Busch Campus.</p> <p> <strong>Prerequisites.</strong> This is a graduate-level course. Students should be comfortable with basic linear algebra, probability, and core machine learning concepts. You should also be able to implement and debug ML experiments in Python (e.g., NumPy, scikit-learn, and PyTorch), including working with real datasets and writing reasonably organized, reproducible code. </p> <p> <strong>Workload.</strong> The class workload will consist of two main components: (1) in-class paper discussions with student-led presentations, and (2) a semester-long course project completed individually or in a small team. The primary deliverable for the course project is a sequence of in-class presentations: a project proposal, a mid-project review, and a final presentation. These presentations (slides + discussion) serve as the main “report” of the project. Teams may optionally submit a longer written report (PDF) with additional technical details, experiments, or analysis. </p> <p><strong>Schedule.</strong> The schedule below is tentative. Topics, readings, and ordering may be adjusted during the semester based on class interests, guest lectures, and pacing.</p> <table style="width:100%; border-collapse:collapse;"> <thead> <tr> <th style="border-bottom:1px solid #ccc; padding:0.6rem; text-align:left;">Week</th> <th style="border-bottom:1px solid #ccc; padding:0.6rem; text-align:left;">Date</th> <th style="border-bottom:1px solid #ccc; padding:0.6rem; text-align:left;">Topic</th> <th style="border-bottom:1px solid #ccc; padding:0.6rem; text-align:left;">Details</th> </tr> </thead> <tbody> <tr> <td style="padding:0.6rem;">1</td> <td style="padding:0.6rem;">January 26</td> <td style="padding:0.6rem;">Introduction (remote)</td> <td style="padding:0.6rem;">Syllabus overview, introduction to interpretability and explainability</td> </tr> <tr> <td style="padding:0.6rem;">2</td> <td style="padding:0.6rem;">February 2</td> <td style="padding:0.6rem;">Global understanding and the human in the loop</td> <td style="padding:0.6rem;">Data visualization, feature importance, exploratory analysis; stakeholders, use cases, and failure modes</td> </tr> <tr> <td style="padding:0.6rem;">3</td> <td style="padding:0.6rem;">February 9</td> <td style="padding:0.6rem;">Interpretability and explainability landscape &amp; project directions</td> <td style="padding:0.6rem;">Overview of project spaces: interpretable models, post-hoc explanations, counterfactuals and recourse, mechanistic interpretability, large language models, and model multiplicity (Rashomon effect)</td> </tr> <tr> <td style="padding:0.6rem;">4</td> <td style="padding:0.6rem;">February 16</td> <td style="padding:0.6rem;">Inherently interpretable models</td> <td style="padding:0.6rem;">Linear models, sparsity, generalized additive models, scoring systems, decision trees, and rule-based models</td> </tr> <tr> <td style="padding:0.6rem;">5</td> <td style="padding:0.6rem;">February 23</td> <td style="padding:0.6rem;">Inherently interpretable models &amp; project proposals</td> <td style="padding:0.6rem;">Prototype-based and concept-based approaches; project proposal presentations</td> </tr> <tr> <td style="padding:0.6rem;">6</td> <td style="padding:0.6rem;">March 2</td> <td style="padding:0.6rem;">Post-hoc explanations I: feature and data attributions</td> <td style="padding:0.6rem;">What feature attributions approximate; local vs. global explanations; LIME, SHAP, gradient-based methods; assumptions and common misuse</td> </tr> <tr> <td style="padding:0.6rem;">7</td> <td style="padding:0.6rem;">March 9</td> <td style="padding:0.6rem;">Post-hoc explanations II: evaluation and pitfalls</td> <td style="padding:0.6rem;">Explanation disagreement, sensitivity to baselines and perturbations, sanity checks, manipulation and robustness</td> </tr> <tr> <td style="padding:0.6rem;"></td> <td style="padding:0.6rem;">March 16</td> <td style="padding:0.6rem;">Spring break</td> <td style="padding:0.6rem;">No class</td> </tr> <tr> <td style="padding:0.6rem;">8</td> <td style="padding:0.6rem;">March 23</td> <td style="padding:0.6rem;">Counterfactual explanations and algorithmic recourse</td> <td style="padding:0.6rem;">Counterfactual definitions; actionability and feasibility; robustness and human constraints</td> </tr> <tr> <td style="padding:0.6rem;">9</td> <td style="padding:0.6rem;">March 30</td> <td style="padding:0.6rem;">Mechanistic interpretability &amp; mid-project updates</td> <td style="padding:0.6rem;">Representations, features, and circuits; how mechanistic interpretability differs from post-hoc explanations; mid-project updates</td> </tr> <tr> <td style="padding:0.6rem;">10</td> <td style="padding:0.6rem;">April 6</td> <td style="padding:0.6rem;">Mechanistic interpretability and large language models</td> <td style="padding:0.6rem;">LLM internals; probing vs. circuits; steering vs. understanding; limits of current approaches</td> </tr> <tr> <td style="padding:0.6rem;">11</td> <td style="padding:0.6rem;">April 13</td> <td style="padding:0.6rem;">Understanding and reasoning in large language models</td> <td style="padding:0.6rem;">Chain-of-thought and explanation-based prompting; faithfulness vs. usefulness of explanations; reasoning, abstraction, and failure modes</td> </tr> <tr> <td style="padding:0.6rem;">12</td> <td style="padding:0.6rem;">April 20</td> <td style="padding:0.6rem;">Multiplicity, underspecification, and the Rashomon effect</td> <td style="padding:0.6rem;">Model sets rather than single models; why explanations do not resolve ambiguity; implications for fairness and trust</td> </tr> <tr> <td style="padding:0.6rem;">13</td> <td style="padding:0.6rem;">April 27</td> <td style="padding:0.6rem;">Interpretability, trustworthiness, and deployment</td> <td style="padding:0.6rem;">Fairness, robustness, privacy, unlearning; regulation, accountability, and open problems</td> </tr> <tr> <td style="padding:0.6rem;">14</td> <td style="padding:0.6rem;">May 4</td> <td style="padding:0.6rem;">Final project presentations</td> <td style="padding:0.6rem;">In-class final presentations</td> </tr> </tbody> </table> <p></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Lesia Semenova. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme (<a href="https://github.com/AbstractGeek/ag-folio" rel="external nofollow noopener" target="_blank">ag-folio</a> adaptation). Last updated: January 05, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>